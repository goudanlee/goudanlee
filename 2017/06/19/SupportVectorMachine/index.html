<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="goudanlee's blog"><title>机器学习常见算法之支持向量机SVM | GoudanLee</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习常见算法之支持向量机SVM</h1><a id="logo" href="/.">GoudanLee</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习常见算法之支持向量机SVM</h1><div class="post-meta">Jun 19, 2017<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span></div><a data-disqus-identifier="2017/06/19/SupportVectorMachine/" href="/2017/06/19/SupportVectorMachine/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>支持向量机，因其英文名为support vector machine，故一般简称SVM，通俗来讲，它是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化为一个凸二次规划问题的求解。
<a id="more"></a></p>
<h3 id="什么是支持向量机模型"><a href="#什么是支持向量机模型" class="headerlink" title="什么是支持向量机模型"></a>什么是支持向量机模型</h3><p>支持向量机（SVM）是一种有监督学习的算法，它可以用来处理分类和回归的问题。然而，实际应用中，SVM 主要用来处理分类问题。在这个算法中，首先我们将所有点画在一个 n 维空间中（其中 n 代表特征个数）。然后我们通过寻找较好区分两类样本的超平面来对数据进行分类处理（如下图所示）。
<img src="/2017/06/19/SupportVectorMachine/1.png" alt="&nbsp" title="&nbsp"></p>
<p>支持向量是观测值的坐标，支持向量机是隔离两个类别的最佳边界（超平面）。</p>
<p><a href="http://www.analyticsvidhya.com/blog/2014/10/support-vector-machine-simplified/" target="_blank" rel="external">这里</a>可以看到关于支持向量的定义和一些实例。</p>
<h3 id="支持向量机的运行原理"><a href="#支持向量机的运行原理" class="headerlink" title="支持向量机的运行原理"></a>支持向量机的运行原理</h3><p>首先，我们已经熟悉了如何利用超平面来区分两个类别的数据。如今急需解决的问题是：“如何找出最佳的超平面？”不要担心，它没有你所想的那么困难！</p>
<p>让我们来看几个例子：</p>
<p><strong>场景一：</strong>首先，我们有三个超平面（A、B 和 C）。现在我们需要的是找出区分星星和圆圈的最佳超平面。</p>
<img src="/2017/06/19/SupportVectorMachine/2.png" alt="&nbsp" title="&nbsp">
<p>你需要记住一个识别最佳超平面的经验法则：“选择能更好区分两个类别的超平面。”在这个例子中，超平面“B”是最佳分割平面。</p>
<p><strong>场景二：</strong>首先我们有三个超平面（A、B 和 C），它们都很好地区分两个类别的数据。那么我们要如何选出最佳的超平面呢？
<img src="/2017/06/19/SupportVectorMachine/3.png" alt="&nbsp" title="&nbsp"></p>
<p>在这里，我们可以通过最大化超平面和其最近的各个类别中数据点的距离来寻找最佳超平面。这个距离我们称之为边际距离。
<img src="/2017/06/19/SupportVectorMachine/4.png" alt="&nbsp" title="&nbsp"></p>
<p>从上图中你可以看到超平面 C 的边际距离最大。因此，我们称 C 为最佳超平面。选择具有最大边际距离的超平面的做法是稳健的。如果我们选择其他超平面，将存在较高的错分率。</p>
<p><strong>场景三：</strong>利用之前章节提到的规则来识别最佳超平面
<img src="/2017/06/19/SupportVectorMachine/5.png" alt="&nbsp" title="&nbsp"></p>
<p>或许你们会选择具有较大边际距离的超平面 B。但是你们错了，SVM 选择超平面时更看重分类的准确度。在上图中，超平面 B 存在一个错分点而超平面 A 的分类则全部正确。因此，最佳超平面是 A。</p>
<p><strong>场景四：</strong>由于存在异常值，我们无法通过一条直线将这两类数据完全区分开来。
<img src="/2017/06/19/SupportVectorMachine/6.png" alt="&nbsp" title="&nbsp"></p>
<p>正如之前提到的，另一端的星星可以被视为异常值。SVM 可以忽略异常值并寻找具有最大边际距离的超平面。因此，我们可以说 SVM 模型在处理异常值时具有鲁棒性。</p>
<p><strong>场景五：</strong>在这个场景中，我们无法通过线性超平面区分这两类数据，那么 SVM 是如何对这种数据进行分类的呢？
<img src="/2017/06/19/SupportVectorMachine/7.png" alt="&nbsp" title="&nbsp"></p>
<p>SVM 模型可以非常容易地解决这个问题。通过引入新的变量信息，我们可以很容易地搞定这个问题。比如我们引入新的变量
$$z=x^2 + y^2$$</p>
<p>然后我们对 x 和 z 构建散点图：
<img src="/2017/06/19/SupportVectorMachine/8.png" alt="&nbsp" title="&nbsp"></p>
<p>从上图中我们可以看出：</p>
<p>由于</p>
<p>$$ z=x^2 + y^2 $$</p>
<p>所以变量 z 恒大于零。</p>
<p>原始图中，红圈数据分布在原点附近，它们的 z 值比较小；而星星数据则远离原点区域，它们具有较大的 z 值。</p>
<p>在 SVM 模型中，我们可以很容易地找到分割两类数据的线性超平面。但是另外一个急需解决的问题是：我们应该手动增加变量信息从而获得该线性超平面分割吗？答案是否定的！SVM 模型有一个工具叫做 kernel trick。该函数可以将输入的低维空间信息转化为高维空间信息。在解决非线性分割问题时，我们经常用到这个函数。简单地说，该函数可以转换一些极其复杂的数据，然后根据自己所定义的标签或输出结果寻找区分数据的超平面。</p>
<p>我们可以在原始图中画出最佳超平面：
<img src="/2017/06/19/SupportVectorMachine/9.png" alt="&nbsp" title="&nbsp"></p>
<h3 id="如何利用-Python-实现-SVM-模型？"><a href="#如何利用-Python-实现-SVM-模型？" class="headerlink" title="如何利用 Python 实现 SVM 模型？"></a>如何利用 Python 实现 SVM 模型？</h3><p>在 Python 中，scikit-learn 是一个被广泛使用的机器学习算法库。我们可以通过 scikit-learn 库来构建 SVM 模型。
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</div><div class="line">X = [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]</div><div class="line">y = [<span class="number">0</span>, <span class="number">1</span>]</div><div class="line">clf = svm.SVC()</div><div class="line">clf.fit(X, y)  </div><div class="line"></div><div class="line">SVC(C=<span class="number">1.0</span>, cache_size=<span class="number">200</span>, class_weight=<span class="keyword">None</span>, coef0=<span class="number">0.0</span>,</div><div class="line">    decision_function_shape=<span class="keyword">None</span>, degree=<span class="number">3</span>, gamma=<span class="string">'auto'</span>, kernel=<span class="string">'rbf'</span>,</div><div class="line">    max_iter=<span class="number">-1</span>, probability=<span class="keyword">False</span>, random_state=<span class="keyword">None</span>, shrinking=<span class="keyword">True</span>,</div><div class="line">    tol=<span class="number">0.001</span>, verbose=<span class="keyword">False</span>)</div><div class="line"></div><div class="line">After being fitted, the model can then be used to predict new values:</div><div class="line"></div><div class="line">clf.predict([[<span class="number">2.</span>, <span class="number">2.</span>]])</div><div class="line">array([<span class="number">1</span>])</div></pre></td></tr></table></figure></p>
<h3 id="如何调整-SVM-模型的参数？"><a href="#如何调整-SVM-模型的参数？" class="headerlink" title="如何调整 SVM 模型的参数？"></a>如何调整 SVM 模型的参数？</h3><p>有效地调节机器学习算法的参数可以提高模型的表现力。让我们来看看 SVM 模型的可用参数列表：
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">class sklearn.svm.SVC<span class="params">(<span class="attr">C</span>=1.0, <span class="attr">kernel</span>='rbf', <span class="attr">degree</span>=3, <span class="attr">gamma</span>='auto', <span class="attr">coef0</span>=0.0, <span class="attr">shrinking</span>=True, <span class="attr">probability</span>=False, <span class="attr">tol</span>=0.001, <span class="attr">cache_size</span>=200, <span class="attr">class_weight</span>=None, <span class="attr">verbose</span>=False, <span class="attr">max_iter</span>=-1, <span class="attr">decision_function_shape</span>=None, <span class="attr">random_state</span>=None)</span>[source]</div></pre></td></tr></table></figure></p>
<p>接下来我将要讨论 SVM 模型中一些比较重要的参数：“kernel”，“gamma”和“C”。</p>
<p>kernel：我们之前已经讨论过这个问题。Kernel参数中具有多个可选项：“linear”，“rbf”和“poly”等（默认值是“rbf”）。其中 “rbf”和“poly”通常用于拟合非线性超平面。下面是一个例子：我们利用线性核估计­对鸢尾花数据进行分类。</p>
<h4 id="例子：线性核估计"><a href="#例子：线性核估计" class="headerlink" title="例子：线性核估计"></a>例子：线性核估计</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets</div><div class="line"></div><div class="line"><span class="comment"># import some data to play with</span></div><div class="line">iris = datasets.load_iris()</div><div class="line">X = iris.data[:, :<span class="number">2</span>] <span class="comment"># we only take the first two features. We could</span></div><div class="line"> <span class="comment"># avoid this ugly slicing by using a two-dim dataset</span></div><div class="line">y = iris.target</div><div class="line"></div><div class="line"><span class="comment"># we create an instance of SVM and fit out data. We do not scale our</span></div><div class="line"><span class="comment"># data since we want to plot the support vectors</span></div><div class="line">C = <span class="number">1.0</span> <span class="comment"># SVM regularization parameter</span></div><div class="line">svc = svm.SVC(kernel=<span class="string">'linear'</span>, C=<span class="number">1</span>,gamma=<span class="number">0</span>).fit(X, y)</div><div class="line"></div><div class="line"><span class="comment"># create a mesh to plot in</span></div><div class="line">x_min, x_max = X[:, <span class="number">0</span>].min() - <span class="number">1</span>, X[:, <span class="number">0</span>].max() + <span class="number">1</span></div><div class="line">y_min, y_max = X[:, <span class="number">1</span>].min() - <span class="number">1</span>, X[:, <span class="number">1</span>].max() + <span class="number">1</span></div><div class="line">h = (x_max / x_min)/<span class="number">100</span></div><div class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, h),</div><div class="line"> np.arange(y_min, y_max, h))</div><div class="line"> </div><div class="line">plt.subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])</div><div class="line">Z = Z.reshape(xx.shape)</div><div class="line">plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=<span class="number">0.8</span>)</div><div class="line"></div><div class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=plt.cm.Paired)</div><div class="line">plt.xlabel(<span class="string">'Sepal length'</span>)</div><div class="line">plt.ylabel(<span class="string">'Sepal width'</span>)</div><div class="line">plt.xlim(xx.min(), xx.max())</div><div class="line">plt.title(<span class="string">'SVC with linear kernel'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<img src="/2017/06/19/SupportVectorMachine/10.png" alt="&nbsp" title="&nbsp">
<h4 id="例子：rbf-核估计"><a href="#例子：rbf-核估计" class="headerlink" title="例子：rbf 核估计"></a>例子：rbf 核估计</h4><p>我们可以通过下面的代码调用 rbf 核估计，并观察其拟合结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">svc = svm.SVC(kernel=<span class="string">'rbf'</span>, C=<span class="number">1</span>,gamma=<span class="number">0</span>).fit(X, y)</div></pre></td></tr></table></figure>
<img src="/2017/06/19/SupportVectorMachine/11.png" alt="&nbsp" title="&nbsp">
<p>当变量个数比较大时（大于1000），我建议你最好使用线性核估计，因为在高维空间中数据大多是线性可分的。当然你也可以利用 rbf 核估计，不过你必须使用交叉验证调整参数从而避免过度拟合。</p>
<p>“gamma”：“rbf”，“poly”和“sigmoid”的核估计系数。gamma的取值越大，越容易出现过度拟合的问题。</p>
<h4 id="例子：比较不同gamma取值下模型的拟合结果"><a href="#例子：比较不同gamma取值下模型的拟合结果" class="headerlink" title="例子：比较不同gamma取值下模型的拟合结果"></a>例子：比较不同gamma取值下模型的拟合结果</h4><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">svc = svm.SVC<span class="params">(<span class="attr">kernel</span>='rbf', <span class="attr">C</span>=1,<span class="attr">gamma</span>=0)</span><span class="string">.fit</span><span class="params">(X, y)</span></div></pre></td></tr></table></figure>
<img src="/2017/06/19/SupportVectorMachine/12.png" alt="&nbsp" title="&nbsp">
<p>C：误差项的惩罚参数。我们可以通过调节该参数达到平衡分割边界的平滑程度和分类准确率的目的。
<img src="/2017/06/19/SupportVectorMachine/13.png" alt="&nbsp" title="&nbsp"></p>
<p>我们应该经常关注交叉验证结果从而有效地利用这些参数的组合避免过度拟合情况的问题。</p>
<h3 id="SVM-模型的优缺点"><a href="#SVM-模型的优缺点" class="headerlink" title="SVM 模型的优缺点"></a>SVM 模型的优缺点</h3><p><strong>优点：</strong></p>
<ol>
<li>它的分类效果非常好。</li>
<li>它可以有效地处理高维空间数据。</li>
<li>它可以有效地处理变量个数大于样本个数的数据。</li>
<li>它只利用一部分子集来训练模型，所以 SVM 模型不需要太大的内存。</li>
</ol>
<p><strong>缺点：</strong></p>
<ol>
<li>它无法很好地处理大规模数据集，因为此时它需要较长的训练时间。</li>
<li>同时它也无法处理包含太多噪声的数据集。</li>
<li>SVM 模型并没有直接提供概率估计值，而是利用比较耗时的五倍交叉验证估计量。</li>
</ol>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.zhihu.com/question/21094489" target="_blank" rel="external">支持向量机(SVM)是什么意思？——知乎</a></p>
<p><a href="https://www.analyticsvidhya.com/blog/2015/10/understaing-support-vector-machine-example-code/" target="_blank" rel="external">支持向量机实例讲解</a></p>
<p><a href="https://zh.wikipedia.org/wiki/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA" target="_blank" rel="external">wikipedia/wiki/SupportVectorMachine ——维基百科</a></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://goudanlee.com/2017/06/19/SupportVectorMachine/" data-id="cj4dj6ww1001gyt9kvstohd24" class="article-share-link">分享</a><div class="tags"><a href="/tags/DAND/">DAND</a><a href="/tags/机器学习/">机器学习</a><a href="/tags/SVM/">SVM</a></div><div class="post-nav"><a href="/2017/06/19/线性回归的R-square/" class="pre">线性回归的R-square</a><a href="/2017/06/13/NavieBayes/" class="next">机器学习常见算法之朴素贝叶斯(Navie Bayes)</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论 「请确保 disqus.com 可以正常加载」</button></div><script>var disqus_shortname = 'goudanlee-com';
var disqus_identifier = '2017/06/19/SupportVectorMachine/';
var disqus_title = '机器学习常见算法之支持向量机SVM';
var disqus_url = 'http://goudanlee.com/2017/06/19/SupportVectorMachine/';
$('.btn_click_load').click(function() {
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
  $('.btn_click_load').css('display','none');
});
$.ajax({
  url: 'https://disqus.com/favicon.ico',
  timeout: 3000,
  type: 'GET',
  success: (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    $('.btn_click_load').css('display','none');
  })(),
  error: function() {
    $('.btn_click_load').css('display','block');
  }
});</script><script id="dsq-count-scr" src="//goudanlee-com.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/DAND/">DAND</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Oracle/">Oracle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/R/">R</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Shell/">Shell</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据分析/">数据分析</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/算法/" style="font-size: 12.14px;">算法</a> <a href="/tags/Python/" style="font-size: 22.86px;">Python</a> <a href="/tags/lxml/" style="font-size: 10px;">lxml</a> <a href="/tags/R/" style="font-size: 16.43px;">R</a> <a href="/tags/DAND/" style="font-size: 20.71px;">DAND</a> <a href="/tags/数据分析/" style="font-size: 18.57px;">数据分析</a> <a href="/tags/HEXO/" style="font-size: 10px;">HEXO</a> <a href="/tags/Redhat/" style="font-size: 12.14px;">Redhat</a> <a href="/tags/CentOS/" style="font-size: 12.14px;">CentOS</a> <a href="/tags/Linux/" style="font-size: 16.43px;">Linux</a> <a href="/tags/Oracle/" style="font-size: 25px;">Oracle</a> <a href="/tags/机器学习/" style="font-size: 16.43px;">机器学习</a> <a href="/tags/BeatifulSoup/" style="font-size: 10px;">BeatifulSoup</a> <a href="/tags/朴素贝叶斯/" style="font-size: 10px;">朴素贝叶斯</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/MongoDB/" style="font-size: 10px;">MongoDB</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Shell/" style="font-size: 14.29px;">Shell</a> <a href="/tags/Zabbix/" style="font-size: 10px;">Zabbix</a> <a href="/tags/特征缩放/" style="font-size: 10px;">特征缩放</a> <a href="/tags/Data-scientist/" style="font-size: 10px;">Data scientist</a> <a href="/tags/线性回归/" style="font-size: 10px;">线性回归</a> <a href="/tags/靈魂歌手/" style="font-size: 10px;">靈魂歌手</a> <a href="/tags/Pandas/" style="font-size: 10px;">Pandas</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/06/22/机器学习中的特征缩放（feature-scaling）/">机器学习中的特征缩放（feature scaling）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/19/线性回归的R-square/">线性回归的R-square</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/19/SupportVectorMachine/">机器学习常见算法之支持向量机SVM</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/13/NavieBayes/">机器学习常见算法之朴素贝叶斯(Navie Bayes)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/09/WineQualityReds/">WineQualityReds EDA</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/07/Histogram-how-to-select-bins/">Histogram how to select bins</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/01/靈魂歌手/">靈魂歌手</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/25/Correlation-Pearson-Kendall-Spearman/">Pearson, Kendall, Spearman三种相关性的差异</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/21/R-operators/">R 逻辑操作符</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/20/dand-osm/">DAND“整理 OpenStreetMap 数据”学习总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> 最近评论</i></div><script type="text/javascript" src="//goudanlee-com.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/goudanlee/goudanlee.github.io" title="github" target="_blank">github</a><ul></ul><a href="https://sites.google.com/site/junwu02/beautyofmathematics" title="数学之美 | Jun Wu's" target="_blank">数学之美 | Jun Wu's</a><ul></ul><a href="https://sites.google.com/site/junwu02/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85" title="浪潮之巅 | Jun Wu's" target="_blank">浪潮之巅 | Jun Wu's</a><ul></ul><a href="http://www.liaoxuefeng.com/" title="liaoxuefeng" target="_blank">liaoxuefeng</a><ul></ul><a href="http://blog.codinglabs.org/?utm_source=cnblogs&amp;utm_medium=banner" title="CodingLabs" target="_blank">CodingLabs</a><ul></ul><a href="http://www.woshipm.com/tag/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90" title="数据分析 | 人人都是产品经理" target="_blank">数据分析 | 人人都是产品经理</a><ul></ul><a href="http://www.36dsj.com/archives/tag/1" title="36大数据" target="_blank">36大数据</a><ul></ul><a href="https://zhuanlan.zhihu.com/dataanalyst" title="某摄影电影编程在学留级生的知乎专栏" target="_blank">某摄影电影编程在学留级生的知乎专栏</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2017 <a href="/." rel="nofollow">GoudanLee.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>